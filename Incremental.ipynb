{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input diction: guinness\n",
      "\n",
      "(('Discovery', 24), ('The', 23), ('Edge', 14))\n",
      "(('Travel', 79), ('Food', 45), ('Expert', 28))\n",
      "(('FWA', 28), ('project', 23), ('The', 12))\n",
      "(('nbsp', 72), ('nbspDownload', 24), ('details', 24))\n",
      "(('Records', 16), ('World', 16), ('Guinness', 15))\n",
      "\n",
      "1 :  http://www.guinnessworldrecords.com\n",
      "2 :  http://itc.conversationsnetwork.org\n",
      "3 :  http://www.about.com\n",
      "4 :  http://www.discovery.com\n",
      "5 :  http://www.thefwa.com\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import operator\n",
    "\n",
    "def incremental(str):\n",
    "    \n",
    "    source = urllib2.urlopen(str).read()\n",
    "\n",
    "    \n",
    "    newSource=''\n",
    "    index = 0\n",
    "\n",
    "    while index<len(source):   #주석 처리 부분\n",
    "        if source[index:index+4] == '<!--':\n",
    "            while not(source[index:index+3]=='-->'):\n",
    "                index = index + 1\n",
    "            index= index +3\n",
    "        else:\n",
    "            newSource= newSource + source[index]\n",
    "            index = index+ 1\n",
    "   \n",
    "\n",
    "\n",
    "    isInTag=True        #태그 제거 함수 \n",
    "    wordList = \"\"\n",
    "    for i in newSource:\n",
    "        if i == '<':\n",
    "            isInTag = False\n",
    "            continue\n",
    "        if i == '>':\n",
    "            isInTag = True\n",
    "            continue\n",
    "        if i == '!' or i == '\"' or i == '#' or i == '$' or i == '%' or i == '&' or i == '\\'' or i == '(' or\\\n",
    "        i == ')' or i == '*' or i == '+' or i == ',' or i == '-' or i == '.' or i == '/' or i == ':' or\\\n",
    "        i == ';' or i == '=' or i == '?' or i == '@' or i == '[' or i == ']' or i == '^' or i == '_' or\\\n",
    "        i == '{' or i == '|' or i == '}' or i == '~':\n",
    "            i == '  '\n",
    "            continue\n",
    "        if isInTag:\n",
    "            wordList += i\n",
    "        \n",
    "\n",
    "    f = open('stopword.txt','r')\n",
    "    f = f.read()\n",
    "    f = f.split()\n",
    "    #print f\n",
    "    wordList = wordList.split()\n",
    "    w1 = ''\n",
    "    for i in wordList:\n",
    "        if i in f:\n",
    "            i = '\\t' # 불용어가 있으면 공백표시\n",
    "        w1 =  w1 + '\\t' + i #불용어가 아니면 추가\n",
    "\n",
    "    w= w1.split() \n",
    "\n",
    "    Dict = {}\n",
    "    for x in range(len(w)):\n",
    "        Dict[w[x]] = w.count(w[x]) \n",
    "    \n",
    "    URL = str\n",
    "    URL = URL[7:len(str)]+'.html' #html 파일 생성\n",
    "    \n",
    "    html = urllib2.urlopen(str).read()\n",
    "    saveHtml = open(URL,'w+')\n",
    "    saveHtml.write(html) #html에 파일 쓰기\n",
    "    #msg = repr([x.encode('utf-8') for x in w]).decode('string-escape')\n",
    "    \n",
    "    URL2 = URL + '.words.frequency' #frequency 파일 생성\n",
    "    FILE = open(URL2,'w')\n",
    "    pickle.dump(Dict,FILE)\n",
    "    FILE.close()\n",
    "    \n",
    "    FILE = open(URL2)\n",
    "    FILE2 = pickle.load(FILE)\n",
    "    sorted_FILE2 = sorted(FILE2.items(), key=operator.itemgetter(1))\n",
    "    ThreeDict= sorted_FILE2[len(sorted_FILE2)-1],sorted_FILE2[len(sorted_FILE2)-2],sorted_FILE2[len(sorted_FILE2)-3]\n",
    "    print ThreeDict\n",
    "    return ThreeDict\n",
    "    \n",
    "Diction = raw_input(\"input diction: \")\n",
    "print\n",
    "def DicTion(str):\n",
    "    Dic = incremental(str)\n",
    "    Dic2 = Dic[0][0].lower() + \" \" + Dic[1][0].lower()+ \" \" +Dic[2][0].lower()\n",
    "    return Dic2\n",
    " \n",
    "Dic2 = DicTion('http://www.discovery.com') #함수 호출\n",
    "Dic3 = DicTion('http://www.about.com')\n",
    "Dic4 = DicTion('http://www.thefwa.com')\n",
    "Dic5 = DicTion('http://itc.conversationsnetwork.org')\n",
    "Dic6 = DicTion('http://www.guinnessworldrecords.com')\n",
    "\n",
    "similarity={}\n",
    "\n",
    "\n",
    "if Diction in Dic2: # 순서 매기기\n",
    "    similarity[1] = 'http://www.discovery.com'\n",
    "    similarity[2] = 'http://itc.conversationsnetwork.org'\n",
    "    similarity[3] = 'http://www.guinnessworldrecords.com'\n",
    "    similarity[4] = 'http://www.about.com'\n",
    "    similarity[5] = 'http://www.thefwa.com'\n",
    "    \n",
    "elif Diction in Dic3:\n",
    "    similarity[1] = 'http://www.about.com'\n",
    "    similarity[2] = 'http://itc.conversationsnetwork.org'\n",
    "    similarity[3] = 'http://www.guinnessworldrecords.com'\n",
    "    similarity[4] = 'http://www.discovery.com'\n",
    "    similarity[5] = 'http://www.thefwa.com'\n",
    "elif Diction in Dic4:\n",
    "    similarity[1] = 'http://www.thefwa.com'\n",
    "    similarity[2] = 'http://www.guinnessworldrecords.com'\n",
    "    similarity[3] = 'http://itc.conversationsnetwork.org'\n",
    "    similarity[4] = 'http://www.discovery.com'\n",
    "    similarity[5] = 'http://www.about.com'\n",
    "elif Diction in Dic5:\n",
    "    similarity[1] = 'http://itc.conversationsnetwork.org'\n",
    "    similarity[2] = 'http://www.about.com'\n",
    "    similarity[3] = 'http://www.guinnessworldrecords.com'\n",
    "    similarity[4] = 'http://www.discovery.com'\n",
    "    similarity[5] = 'http://www.thefwa.com'\n",
    "elif Diction in Dic6:\n",
    "    similarity[1] = 'http://www.guinnessworldrecords.com'\n",
    "    similarity[2] = 'http://itc.conversationsnetwork.org'\n",
    "    similarity[3] = 'http://www.about.com'\n",
    "    similarity[4] = 'http://www.discovery.com'\n",
    "    similarity[5] = 'http://www.thefwa.com'\n",
    "else:\n",
    "    print \"연관 URL이 없습니다.\"\n",
    "\n",
    "print\n",
    "\n",
    "for key, value in similarity.items():\n",
    "    print key, ': ' ,value\n",
    "\n",
    "\n",
    "\n",
    "#incremental('http://www.about.com')\n",
    "#incremental('http://itc.conversationsnetwork.org')\n",
    "#incremental('http://www.discovery.com')\n",
    "#incremental('http://www.thefwa.com')\n",
    "#incremental('http://www.guinnessworldrecords.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Project\n",
    "\n",
    "사전부터 시작했습니다. 영어 불용어를 저장했는데, \n",
    "\n",
    "\n",
    "var,0,1,2,3,4,5,6,7,8,9,fuction 를 추가해서 불용어를 제거했습니다.\n",
    "\n",
    "\n",
    "그 후 (1) str + .html 형식으로 파일을 만들었습니다. http:// 는 슬라이싱,인덱싱\n",
    "\n",
    "\n",
    "이용하여 제거 했습니다.\n",
    "\n",
    "\n",
    "그 후 단어의 출현빈도를 pickle을 이용해서 저장하고 로드해서 변수에 저장하고 출력\n",
    "\n",
    "\n",
    "하는 것까지의 과정을 함수로 만들었습니다.\n",
    "\n",
    "\n",
    "그리고 5개의 각각 웹사이트를 함수 매개변수로 해서 각 사전의 단어와 수를 출력했습니다.\n",
    "\n",
    "\n",
    "마지막으로 단어를 입력 하면, 각각 사전의 단어들을 str형변환 시켜서\n",
    "\n",
    "\n",
    "단어 검사를 한 후 있는 것은 순서를 매겨 출력하도록 했습니다.\n",
    "\n",
    "\n",
    "그렇지 않은 경우에는 임의로 순서를 매겨서 출력하도록 했습니다.\n",
    "\n",
    "\n",
    "완성도 높은 검색로봇 기능이 되려면 제 생각으로는\n",
    "\n",
    "\n",
    "1) 입력을 할 시에 비슷한 단어가 있으면 같이 출력하도록 한다.\n",
    "\n",
    "2) 틀리게 입력을 했을 때 맞는 단어로 고치도록 하는 것.\n",
    "\n",
    "3) 연관 사이트를 검색해서 출력하는 것 \n",
    "\n",
    "이 3가지가 생각나여 제시했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
